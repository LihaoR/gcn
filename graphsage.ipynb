{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from networkx import to_numpy_matrix, karate_club_graph\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zkc = karate_club_graph()\n",
    "order = sorted(list(zkc.nodes()))\n",
    "A = to_numpy_matrix(zkc, nodelist=order)\n",
    "I = np.eye(zkc.number_of_nodes())          \n",
    "A_hat = A + I\n",
    "D_hat = np.array(np.sum(A_hat, axis=0))[0] # 度矩阵\n",
    "D_hat_ = np.array(np.diag(D_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "dic = {}\n",
    "dic['Officer'] = 0\n",
    "dic['Mr. Hi'] = 1\n",
    "labels = np.zeros((len(zkc), 2))\n",
    "for i in range(len(zkc)):\n",
    "    if dic[zkc.nodes[i]['club']] == 0:\n",
    "        labels[i][0] = 1\n",
    "        labels[i][1] = 0\n",
    "    else:\n",
    "        labels[i][0] = 0\n",
    "        labels[i][1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(inputs, nodes, neighbors):\n",
    "    node_feat = tf.nn.embedding_lookup(inputs, nodes)\n",
    "    neighbors_feat = tf.nn.embedding_lookup(inputs, neighbors)\n",
    "    \n",
    "    concat_feat = tf.concat([node_feat, neighbors_feat], axis=1)\n",
    "    concat_mean = tf.reduce_mean(concat_feat, axis=1)\n",
    "    \n",
    "    unit = inputs_features.get_shape().as_list()\n",
    "    tmp = slim.fully_connected(concat_mean, 1156, activation_fn=tf.nn.relu)\n",
    "    outputs = tf.reduce_mean(tf.reshape(tmp,[-1,34,34]),axis=0)\n",
    "    return outputs, tmp\n",
    "\n",
    "def graphSAGE(inputs, node_inputs, neighbors_inputs, neighbors_num):\n",
    "    outputs = inputs\n",
    "    for i in range(neighbors_num):\n",
    "        neighbors =  neighbors_inputs[i]\n",
    "        nodes = node_inputs\n",
    "        outputs, tmp = aggregator(outputs, nodes, neighbors)\n",
    "        \n",
    "    outputs_graphSAGE = slim.fully_connected(tmp, 2, activation_fn=tf.nn.softmax)\n",
    "    return outputs_graphSAGE\n",
    "\n",
    "inputs_features = tf.placeholder(shape=[34,34],dtype=tf.float32)\n",
    "inputs_labels = tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "node_inputs = tf.placeholder(shape=[None,1],dtype=tf.int32)\n",
    "neighbors_inputs = []\n",
    "for i in range(len(D_hat)):\n",
    "    neighbors_inputs.append(tf.placeholder(shape=[None,D_hat[i]],dtype=tf.int32, name='tensor'+str(i)))\n",
    "\n",
    "outputs_graphSAGE = graphSAGE(inputs_features, node_inputs, neighbors_inputs, len(D_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=outputs_graphSAGE, labels=inputs_labels))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_batch():\n",
    "    I_feed = np.expand_dims([x for x in range(34)],axis=-1)\n",
    "    feed_dicts = {inputs_features:A_hat, node_inputs:I_feed, inputs_labels:labels}\n",
    "    \n",
    "    for i in range(len(neighbors_inputs)):\n",
    "        y = np.argwhere(A_hat[i] > 0)\n",
    "        z = []\n",
    "        for j in range(len(y)):\n",
    "            z.append(y[j][1])\n",
    "        feed_dicts[neighbors_inputs[i]] = [np.array(z) for _ in range(34)]\n",
    "    return feed_dicts\n",
    "\n",
    "def get_feed(y):\n",
    "    I_feed = np.expand_dims([y],axis=-1)\n",
    "    feed_dicts = {inputs_features:A_hat, node_inputs:I_feed, inputs_labels:[labels[y]]}\n",
    "\n",
    "    for i in range(len(neighbors_inputs)):\n",
    "        y = np.argwhere(A_hat[i] > 0)\n",
    "        z = []\n",
    "        for j in range(len(y)):\n",
    "            z.append(y[j][1])\n",
    "        feed_dicts[neighbors_inputs[i]] = [np.array(z)]\n",
    "    return feed_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 0.6931472\n",
      "epoch 50 0.6930295\n",
      "epoch 100 0.69210947\n",
      "epoch 150 0.6878026\n",
      "last error 0.6719878\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    \"\"\"\n",
    "    for j in range(34):\n",
    "        feed_dicts = get_feed(j)\n",
    "        error, _ = sess.run([loss, opt], feed_dict=feed_dicts)\n",
    "    \"\"\"\n",
    "    feed_dicts = get_feed_batch()\n",
    "    error, _ = sess.run([loss, opt], feed_dict=feed_dicts)\n",
    "    if i % 50 == 0:\n",
    "        print('epoch', i, error)\n",
    "    \n",
    "print('last error', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for j in range(34):\n",
    "    feed_dicts = get_feed(j)\n",
    "    output = sess.run(outputs_graphSAGE, feed_dict=feed_dicts)[0]\n",
    "    preds.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range (34):\n",
    "    if np.argmax(labels[i]) != np.argmax(preds[i]):\n",
    "        c += 1\n",
    "        print(preds[i])\n",
    "print('acc:', 1 - c/34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
